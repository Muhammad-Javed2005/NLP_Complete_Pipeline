{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "261bdcbe",
            "metadata": {},
            "source": [
                "# ***Engr.Muhammad Javed***"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Stop Words\n",
                "\n",
                "## What are Stop Words?\n",
                "Stop words are common words (like 'the', 'is', 'in', 'and') that are often removed from text during preprocessing because they carry less meaningful information for many NLP tasks.\n",
                "\n",
                "## Why Remove?\n",
                "- Reduces dataset size.\n",
                "- Focuses model on meaningful words.\n",
                "\n",
                "## When NOT to Remove?\n",
                "- When context matters (e.g., machine translation, text summarization).\n",
                "- When exact phrase matching is needed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize\n",
                "import pandas as pd\n",
                "\n",
                "# Ensure stopwords are downloaded\n",
                "try:\n",
                "    nltk.data.find('corpora/stopwords')\n",
                "except LookupError:\n",
                "    nltk.download('stopwords')\n",
                "\n",
                "stop_words = set(stopwords.words('english'))\n",
                "print(f\"Number of English stopwords: {len(stop_words)}\")\n",
                "print(list(stop_words)[:10])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Applying Removal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_stopwords(text):\n",
                "    tokens = word_tokenize(text)\n",
                "    return ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
                "\n",
                "sample_text = \"This is a sample sentence showing off the stop words filtration.\"\n",
                "print(\"Original:\", sample_text)\n",
                "print(\"Cleaned:\", remove_stopwords(sample_text))\n",
                "\n",
                "# Apply to dataset\n",
                "df_train = pd.read_csv('../Dataset/train.txt', sep=';', names=['text', 'emotion'])\n",
                "df_train['text_no_stop'] = df_train['text'].apply(remove_stopwords)\n",
                "df_train.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
